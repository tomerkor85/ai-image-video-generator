# ××“×¨×™×š ×¤×¨×™×¡×” ×œ×©×¨×ª×™× ×—×™×¦×•× ×™×™×

## ×©×œ×‘ 1: ×”×¢×œ××ª ×”×¤×¨×•×™×§×˜ ×œ-GitHub

### 1.1 ×™×¦×™×¨×ª Repository ×‘-GitHub
1. ×œ×š ×œ-[GitHub.com](https://github.com)
2. ×œ×—×¥ ×¢×œ "New repository"
3. ×©×: `ai-image-video-generator`
4. ×ª×™××•×¨: `AI Image & Video Generation System with FLUX and WAN LORA`
5. ×‘×—×¨ "Private" ××• "Public" ×œ×¤×™ ×”×¦×•×¨×š
6. **××œ ×ª×¡××Ÿ** "Add a README file" (×›×‘×¨ ×™×© ×œ× ×•)
7. ×œ×—×¥ "Create repository"

### 1.2 ×—×™×‘×•×¨ ×”×¤×¨×•×™×§×˜ ×”××§×•××™ ×œ-GitHub
```bash
# ×”×•×¡×£ ××ª ×”-remote repository
git remote add origin https://github.com/YOUR_USERNAME/ai-image-video-generator.git

# ×”×¢×œ×” ××ª ×”×§×•×“
git branch -M main
git push -u origin main
```

## ×©×œ×‘ 2: ×‘×—×™×¨×ª ×©×¨×ª

### ××¤×©×¨×•×™×•×ª ××•××œ×¦×•×ª:

#### ğŸš€ **RunPod** (××•××œ×¥)
- **×™×ª×¨×•× ×•×ª**: ×–×•×œ, GPU ×—×–×§, ×§×œ ×œ×”×’×“×¨×”
- **××—×™×¨**: $0.2-0.5/×©×¢×”
- **GPU**: RTX 4090, A100
- **×–×™×›×¨×•×Ÿ**: 24GB+ VRAM

#### â˜ï¸ **AWS EC2**
- **×™×ª×¨×•× ×•×ª**: ×××™×Ÿ, ×’××™×©
- **××—×™×¨**: $1-3/×©×¢×”
- **GPU**: V100, A100
- **×–×™×›×¨×•×Ÿ**: 16GB+ VRAM

#### ğŸ”¥ **Google Cloud**
- **×™×ª×¨×•× ×•×ª**: ×‘×™×¦×•×¢×™× ×˜×•×‘×™×
- **××—×™×¨**: $0.8-2/×©×¢×”
- **GPU**: V100, A100
- **×–×™×›×¨×•×Ÿ**: 16GB+ VRAM

## ×©×œ×‘ 3: ×¤×¨×™×¡×” ×¢×œ RunPod

### 3.1 ×™×¦×™×¨×ª Instance
1. ×œ×š ×œ-[RunPod.io](https://runpod.io)
2. ×‘×—×¨ "Deploy" â†’ "RunPod Template"
3. ×‘×—×¨ "PyTorch" template
4. ×‘×—×¨ GPU: **RTX 4090** ××• **A100**
5. ×‘×—×¨ "Start from this template"

### 3.2 ×”×’×“×¨×ª ×”×©×¨×ª
```bash
# ×”×ª×—×‘×¨ ×œ×©×¨×ª ×“×¨×š SSH
ssh root@YOUR_SERVER_IP

# Clone ×”×¤×¨×•×™×§×˜
git clone https://github.com/YOUR_USERNAME/ai-image-video-generator.git
cd ai-image-video-generator

# ×”×¨×¥ ××ª ×¡×§×¨×™×¤×˜ ×”×¤×¨×™×¡×”
chmod +x runpod_deploy.sh
./runpod_deploy.sh
```

### 3.3 ×”×¢×œ××ª ×§×‘×¦×™ LORA
```bash
# ×”×¢×œ×” ××ª ×§×‘×¦×™ ×”-LORA ×©×œ×š
scp -r "flux-lora/" root@YOUR_SERVER_IP:/root/ai-image-video-generator/
scp -r "naya_wan_lora/" root@YOUR_SERVER_IP:/root/ai-image-video-generator/
```

## ×©×œ×‘ 4: ×¤×¨×™×¡×” ×¢×œ AWS EC2

### 4.1 ×™×¦×™×¨×ª Instance
1. ×œ×š ×œ-[AWS Console](https://console.aws.amazon.com)
2. ×‘×—×¨ "EC2" â†’ "Launch Instance"
3. ×‘×—×¨ "Deep Learning AMI (Ubuntu 22.04)"
4. ×‘×—×¨ Instance Type: **g4dn.xlarge** ××• **p3.2xlarge**
5. ×‘×—×¨ "Launch"

### 4.2 ×”×’×“×¨×ª ×”×©×¨×ª
```bash
# ×”×ª×—×‘×¨ ×œ×©×¨×ª
ssh -i your-key.pem ubuntu@YOUR_SERVER_IP

# ×”×ª×§×Ÿ Docker
sudo apt update
sudo apt install docker.io docker-compose
sudo usermod -aG docker ubuntu
sudo systemctl start docker
sudo systemctl enable docker

# Clone ×”×¤×¨×•×™×§×˜
git clone https://github.com/YOUR_USERNAME/ai-image-video-generator.git
cd ai-image-video-generator

# ×”×¨×¥ ×¢× Docker
docker-compose up -d
```

## ×©×œ×‘ 5: ×‘×“×™×§×ª ×”×¤×¨×™×¡×”

### 5.1 ×‘×“×™×§×ª ×¡×˜×˜×•×¡
```bash
# ×‘×“×•×§ ×©×”×©×¨×ª ×¨×¥
curl http://YOUR_SERVER_IP:8000/health

# ×‘×“×•×§ ××ª ×”-API docs
curl http://YOUR_SERVER_IP:8000/docs
```

### 5.2 ×‘×“×™×§×ª ×™×¦×™×¨×ª ×ª××•× ×”
```bash
curl -X POST "http://YOUR_SERVER_IP:8000/generate/image" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "beautiful landscape, detailed, high quality",
    "width": 1024,
    "height": 1024,
    "seed": 42
  }'
```

## ×©×œ×‘ 6: ××•×¤×˜×™××™×–×¦×™×”

### 6.1 ×”×’×“×¨×•×ª ×–×™×›×¨×•×Ÿ
```bash
# ×”×’×“×¨ ××©×ª× ×™ ×¡×‘×™×‘×”
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
export TOKENIZERS_PARALLELISM=false
```

### 6.2 ×”×’×“×¨×•×ª Docker
```yaml
# docker-compose.yml
services:
  ai-generator:
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    deploy:
      resources:
        limits:
          memory: 32G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## ×©×œ×‘ 7: × ×™×˜×•×¨ ×•×ª×—×–×•×§×”

### 7.1 × ×™×˜×•×¨ ×‘×™×¦×•×¢×™×
```bash
# ×‘×“×•×§ ×©×™××•×© ×‘-GPU
nvidia-smi

# ×‘×“×•×§ ×–×™×›×¨×•×Ÿ
free -h

# ×‘×“×•×§ ×œ×•×’×™×
docker logs ai-generator
```

### 7.2 ×’×™×‘×•×™
```bash
# ×’×‘×” ××ª ×”××•×“×œ×™×
tar -czf models_backup.tar.gz flux-lora/ "naya_wan_lora/"

# ×’×‘×” ××ª ×”×¤×œ×˜×™×
tar -czf outputs_backup.tar.gz outputs/
```

## ×©×œ×‘ 8: ××‘×˜×—×”

### 8.1 Firewall
```bash
# ×¤×ª×— ×¨×§ ××ª ×”×¤×•×¨×˜ ×”× ×“×¨×©
sudo ufw allow 8000
sudo ufw enable
```

### 8.2 HTTPS (××•×¤×¦×™×•× ×œ×™)
```bash
# ×”×ª×§×Ÿ nginx ×•-certbot
sudo apt install nginx certbot python3-certbot-nginx

# ×”×’×“×¨ SSL
sudo certbot --nginx -d your-domain.com
```

## ×¤×ª×¨×•×Ÿ ×‘×¢×™×•×ª × ×¤×•×¦×•×ª

### ×©×’×™××ª ×–×™×›×¨×•×Ÿ
```bash
# ×”×¤×¢×œ swap
sudo fallocate -l 16G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

### ×©×’×™××ª CUDA
```bash
# ×‘×“×•×§ ×”×ª×§× ×ª CUDA
nvidia-smi
nvcc --version

# ×”×ª×§×Ÿ ××—×“×© ×× × ×“×¨×©
sudo apt install nvidia-cuda-toolkit
```

### ×©×’×™××ª Docker
```bash
# ×”×¤×¢×œ ××—×“×© Docker
sudo systemctl restart docker

# × ×§×” cache
docker system prune -a
```

## ×¢×œ×•×™×•×ª ××©×•×¢×¨×•×ª

| ×©×¨×ª | GPU | ×–×™×›×¨×•×Ÿ | ××—×™×¨/×©×¢×” | ××—×™×¨/×™×•× |
|------|-----|--------|-----------|----------|
| RunPod | RTX 4090 | 24GB | $0.3 | $7.2 |
| AWS | V100 | 16GB | $1.5 | $36 |
| GCP | A100 | 40GB | $2.0 | $48 |

## ×ª××™×›×”

×œ×©××œ×•×ª ×•×ª××™×›×”:
- ×¦×•×¨ Issue ×‘-GitHub
- ×‘×“×•×§ ××ª ×”×œ×•×’×™×: `docker logs ai-generator`
- ×‘×“×•×§ ××ª ×”×‘×¨×™××•×ª: `curl http://YOUR_SERVER_IP:8000/health`
